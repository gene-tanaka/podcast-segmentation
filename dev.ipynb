{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_dataset import SegmentationDataset\n",
    "from model import Model\n",
    "from baseline import Baseline\n",
    "from metrics import pk, windowdiff\n",
    "import io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import mmap\n",
    "import numpy as np\n",
    "from run import load_vectors, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 999995/999995 [02:45<00:00, 6051.09it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vecModel = load_vectors('wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'saved_model'\n",
    "model = torch.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 50/50 [00:00<00:00, 4102.09it/s]\n",
      "Progress: 100%|██████████| 50/50 [00:00<00:00, 7691.17it/s]\n",
      "Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading raw data...\n",
      "\n",
      "Converting documents to embeddings...\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 50/50 [00:14<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_path = 'wiki_50'\n",
    "dev_dataset = SegmentationDataset(dev_path, word2vecModel)\n",
    "dev_dl = DataLoader(dev_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# total_pk = 0.0\n",
    "# total_windowdiff = 0.0\n",
    "# with tqdm(desc='Validating', total=5) as pbar:\n",
    "#     for i, data in enumerate(dev_dl):\n",
    "#         pbar.update()\n",
    "#         target = torch.flatten(data['target'], start_dim=0, end_dim=1)\n",
    "#         target = target.long()\n",
    "#         output = model(torch.flatten(data['sentences'], start_dim=0, end_dim=1))\n",
    "#         output_softmax = F.softmax(output, 1)\n",
    "#         output_argmax = torch.argmax(output_softmax, dim=1)\n",
    "#         total_pk += pk(target.detach().numpy(), output_argmax.detach().numpy())\n",
    "#         total_windowdiff += windowdiff(target.detach().numpy(), output_softmax.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(dev_dl):\n",
    "    if i == 0:\n",
    "        target = torch.flatten(data['target'], start_dim=0, end_dim=1)\n",
    "        target = target.long()\n",
    "        output = model(torch.flatten(data['sentences'], start_dim=0, end_dim=1))\n",
    "        output_softmax = F.softmax(output, 1)\n",
    "        output_argmax = torch.argmax(output_softmax, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_argmax.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(output_argmax.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pk, windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segeval.window_diff(target.tolist(), output_argmax.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(round(len(target.tolist()) / (target.tolist().count(1) * 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19988770353733856"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(target.tolist(), output_argmax.tolist(), boundary=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19640852974186307"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(target.tolist(), output_argmax.tolist(), k=15, boundary=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pk, total_windowdiff = validate(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'baseline' from '/Users/genetanaka/podcast-segmentation/baseline.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import metrics\n",
    "import baseline\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.1459458282339274, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 0.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.1459458282339274, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 1.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.14535529299862945, Baseline Window Diff: 0.14535529299862945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 2.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.14284588202466034, Baseline Window Diff: 0.14284588202466034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 3.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.13030347263437625, Baseline Window Diff: 0.13030347263437625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 4.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.11583660303029159, Baseline Window Diff: 0.11583660303029159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 5.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([int(ch) for ch in \"000000000100000000000000\"])\n",
    "s2 = np.array([int(ch) for ch in \"000000100100000000000000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1):\n",
    "    \"\"\"\n",
    "    Compute the Pk metric for a pair of segmentations A segmentation\n",
    "    is any sequence over a vocabulary of two items (e.g. \"0\", \"1\"),\n",
    "    where the specified boundary value is used to mark the edge of a\n",
    "    segmentation.\n",
    "\n",
    "    >>> '%.2f' % pk('0100'*100, '1'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0100'*100, 2)\n",
    "    '0.00'\n",
    "    \"\"\"\n",
    "\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))\n",
    "\n",
    "    err = 0.0\n",
    "    for i in range(len(ref) - k + 1):\n",
    "        r = np.count_nonzero(ref[i : i + k] == boundary) > 0\n",
    "        h = np.count_nonzero(hyp[i : i + k] == boundary) > 0\n",
    "        if r != h:\n",
    "            err += 1\n",
    "    return err / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowdiff(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1, weighted: bool = False):\n",
    "    \"\"\"\n",
    "    Compute the windowdiff score for a pair of segmentations.  A\n",
    "    segmentation is any sequence over a vocabulary of two items\n",
    "    (e.g. \"0\", \"1\"), where the specified boundary value is used to\n",
    "    mark the edge of a segmentation.\n",
    "\n",
    "        >>> s1 = \"000100000010\"\n",
    "        >>> s2 = \"000010000100\"\n",
    "        >>> s3 = \"100000010000\"\n",
    "        >>> '%.2f' % windowdiff(s1, s1, 3)\n",
    "        '0.00'\n",
    "        >>> '%.2f' % windowdiff(s1, s2, 3)\n",
    "        '0.30'\n",
    "        >>> '%.2f' % windowdiff(s2, s3, 3)\n",
    "        '0.80'\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))b\n",
    "\n",
    "    if ref.shape[0] != hyp.shape[0]:\n",
    "        raise ValueError(\"Segmentations have unequal length\")\n",
    "    if k > ref.shape[0]:\n",
    "        raise ValueError(\n",
    "            \"Window width k should be smaller or equal than segmentation lengths\"\n",
    "        )\n",
    "    wd = 0.0\n",
    "    for i in range(ref.shape[0] - k + 1):\n",
    "        ndiff = abs(np.count_nonzero(ref[i : i + k] == boundary) - np.count_nonzero(hyp[i : i + k] == boundary))\n",
    "        if weighted:\n",
    "            wd += ndiff\n",
    "        else:\n",
    "            wd += min(1, ndiff)\n",
    "    return wd / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([int(ch) for ch in \"000000000100\"])\n",
    "s2 = np.array([int(ch) for ch in \"000000100100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(s1, s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
