{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_dataset import SegmentationDataset\n",
    "from model import Model\n",
    "from baseline import Baseline\n",
    "from metrics import pk, windowdiff\n",
    "import io\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import mmap\n",
    "import numpy as np\n",
    "from run import load_vectors, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 999995/999995 [02:32<00:00, 6561.99it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vecModel = load_vectors('wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'saved_model'\n",
    "model = torch.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 50/50 [00:00<00:00, 4009.62it/s]\n",
      "Progress: 100%|██████████| 50/50 [00:00<00:00, 7741.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading raw data...\n",
      "\n",
      "Converting documents to embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_path = 'wiki_50'\n",
    "dev_dataset = SegmentationDataset(dev_path, word2vecModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.029342635408848645, Baseline Window Diff: 0.14284588202466034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 3.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:13<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.08482912896314644, Baseline Window Diff: 0.1090323403202254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 6.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.031051749018370114, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 1.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.031051749018370114, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 0.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'baseline' from '/Users/genetanaka/podcast-segmentation/baseline.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import metrics\n",
    "import baseline\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.1459458282339274, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 0.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.1459458282339274, Baseline Window Diff: 0.1459458282339274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 1.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.14535529299862945, Baseline Window Diff: 0.14535529299862945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 2.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.14284588202466034, Baseline Window Diff: 0.14284588202466034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 3.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.13030347263437625, Baseline Window Diff: 0.13030347263437625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 4.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating Baseline:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Pk: 0.11583660303029159, Baseline Window Diff: 0.11583660303029159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_threshold = 5.0\n",
    "baseline = Baseline(dev_dataset, baseline_threshold)\n",
    "base_pk, base_windowdiff = baseline.evaluate()\n",
    "print(\"Baseline Pk: {}, Baseline Window Diff: {}\".format(base_pk, base_windowdiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([int(ch) for ch in \"000000000100000000000000\"])\n",
    "s2 = np.array([int(ch) for ch in \"000000100100000000000000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1):\n",
    "    \"\"\"\n",
    "    Compute the Pk metric for a pair of segmentations A segmentation\n",
    "    is any sequence over a vocabulary of two items (e.g. \"0\", \"1\"),\n",
    "    where the specified boundary value is used to mark the edge of a\n",
    "    segmentation.\n",
    "\n",
    "    >>> '%.2f' % pk('0100'*100, '1'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0100'*100, 2)\n",
    "    '0.00'\n",
    "    \"\"\"\n",
    "\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))\n",
    "\n",
    "    err = 0.0\n",
    "    for i in range(len(ref) - k + 1):\n",
    "        r = np.count_nonzero(ref[i : i + k] == boundary) > 0\n",
    "        h = np.count_nonzero(hyp[i : i + k] == boundary) > 0\n",
    "        if r != h:\n",
    "            err += 1\n",
    "    return err / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowdiff(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1, weighted: bool = False):\n",
    "    \"\"\"\n",
    "    Compute the windowdiff score for a pair of segmentations.  A\n",
    "    segmentation is any sequence over a vocabulary of two items\n",
    "    (e.g. \"0\", \"1\"), where the specified boundary value is used to\n",
    "    mark the edge of a segmentation.\n",
    "\n",
    "        >>> s1 = \"000100000010\"\n",
    "        >>> s2 = \"000010000100\"\n",
    "        >>> s3 = \"100000010000\"\n",
    "        >>> '%.2f' % windowdiff(s1, s1, 3)\n",
    "        '0.00'\n",
    "        >>> '%.2f' % windowdiff(s1, s2, 3)\n",
    "        '0.30'\n",
    "        >>> '%.2f' % windowdiff(s2, s3, 3)\n",
    "        '0.80'\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))b\n",
    "\n",
    "    if ref.shape[0] != hyp.shape[0]:\n",
    "        raise ValueError(\"Segmentations have unequal length\")\n",
    "    if k > ref.shape[0]:\n",
    "        raise ValueError(\n",
    "            \"Window width k should be smaller or equal than segmentation lengths\"\n",
    "        )\n",
    "    wd = 0.0\n",
    "    for i in range(ref.shape[0] - k + 1):\n",
    "        ndiff = abs(np.count_nonzero(ref[i : i + k] == boundary) - np.count_nonzero(hyp[i : i + k] == boundary))\n",
    "        if weighted:\n",
    "            wd += ndiff\n",
    "        else:\n",
    "            wd += min(1, ndiff)\n",
    "    return wd / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([int(ch) for ch in \"000000000100\"])\n",
    "s2 = np.array([int(ch) for ch in \"000000100100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataset):\n",
    "    model.eval()\n",
    "    total_pk = 0.0\n",
    "    total_windowdiff = 0.0\n",
    "    with tqdm(desc='Validating', total=len(dataset)) as pbar:\n",
    "        for data in dataset:\n",
    "            pbar.update()\n",
    "            target = data['target']\n",
    "            target = target.long()\n",
    "            output = model(data['sentences'])\n",
    "            output_softmax = F.softmax(output, 1)\n",
    "            output_argmax = torch.argmax(output_softmax, dim=1)\n",
    "            total_pk += pk(target.detach().numpy(), output_argmax.detach().numpy())\n",
    "            total_windowdiff += windowdiff(target.detach().numpy(), output_softmax.detach().numpy())\n",
    "    return total_pk / len(dataset), total_windowdiff / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:]).astype(np.float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecModel = load_vectors('wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = 'val_data'\n",
    "val_dataset = SegmentationDataset(val_path, word2vecModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'saved_model'\n",
    "model = torch.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 50/50 [06:02<00:00,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "total_pk, total_windowdiff = validate(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11489407921555729"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11489407921555729"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline():\n",
    "    def __init__(self, data, threshold):\n",
    "        self.dataset = data\n",
    "        self.data_len = len(data)\n",
    "        self.threshold = threshold\n",
    "        self.all_labels = []\n",
    "        self.getBaselineLabels()\n",
    "        \n",
    "    def getBaselineLabels(self):\n",
    "        for data in self.dataset:\n",
    "            sentence_labels = [0 for i in range(data['target'].shape[0])]\n",
    "            sentences = data['sentences']\n",
    "            for i in range(1, sentences.shape[0]):\n",
    "                firstSentenceTensor = sentences[i - 1, :, :]\n",
    "                secondSentenceTensor = sentences[i, :, :]\n",
    "                if torch.norm(secondSentenceTensor - firstSentenceTensor).item() > self.threshold:\n",
    "                    sentence_labels[i - 1] = 1\n",
    "            self.all_labels.append(sentence_labels)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        total_pk = 0.0\n",
    "        total_windowdiff = 0.0\n",
    "        with tqdm(desc='Validating Baseline', total=self.data_len) as pbar:\n",
    "            for i in range(self.data_len):\n",
    "                data = self.dataset[i]\n",
    "                pbar.update()\n",
    "                target = data['target']\n",
    "                target = target.long()\n",
    "                pred = self.all_labels[i]\n",
    "                total_pk += pk(target.detach().numpy(), np.array(pred))\n",
    "                total_windowdiff += windowdiff(target.detach().numpy(), np.array(pred))\n",
    "        return total_pk / self.data_len, total_windowdiff / self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = Baseline(val_dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "base_pk, base_windowdiff = b.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04796617029867993"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11583660303029159"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
