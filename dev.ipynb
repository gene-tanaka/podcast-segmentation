{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_dataset import SegmentationDataset\n",
    "from model import Model\n",
    "import io\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1):\n",
    "    \"\"\"\n",
    "    Compute the Pk metric for a pair of segmentations A segmentation\n",
    "    is any sequence over a vocabulary of two items (e.g. \"0\", \"1\"),\n",
    "    where the specified boundary value is used to mark the edge of a\n",
    "    segmentation.\n",
    "\n",
    "    >>> '%.2f' % pk('0100'*100, '1'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0'*400, 2)\n",
    "    '0.50'\n",
    "    >>> '%.2f' % pk('0100'*100, '0100'*100, 2)\n",
    "    '0.00'\n",
    "    \"\"\"\n",
    "\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))\n",
    "\n",
    "    err = 0.0\n",
    "    for i in range(len(ref) - k + 1):\n",
    "        r = np.count_nonzero(ref[i : i + k] == boundary) > 0\n",
    "        h = np.count_nonzero(hyp[i : i + k] == boundary) > 0\n",
    "        if r != h:\n",
    "            err += 1\n",
    "    return err / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowdiff(ref: np.array, hyp: np.array, k: int = None, boundary: int = 1, weighted: bool = False):\n",
    "    \"\"\"\n",
    "    Compute the windowdiff score for a pair of segmentations.  A\n",
    "    segmentation is any sequence over a vocabulary of two items\n",
    "    (e.g. \"0\", \"1\"), where the specified boundary value is used to\n",
    "    mark the edge of a segmentation.\n",
    "\n",
    "        >>> s1 = \"000100000010\"\n",
    "        >>> s2 = \"000010000100\"\n",
    "        >>> s3 = \"100000010000\"\n",
    "        >>> '%.2f' % windowdiff(s1, s1, 3)\n",
    "        '0.00'\n",
    "        >>> '%.2f' % windowdiff(s1, s2, 3)\n",
    "        '0.30'\n",
    "        >>> '%.2f' % windowdiff(s2, s3, 3)\n",
    "        '0.80'\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = int(round(ref.shape[0] / (np.count_nonzero(ref == boundary) * 2.0)))b\n",
    "\n",
    "    if ref.shape[0] != hyp.shape[0]:\n",
    "        raise ValueError(\"Segmentations have unequal length\")\n",
    "    if k > ref.shape[0]:\n",
    "        raise ValueError(\n",
    "            \"Window width k should be smaller or equal than segmentation lengths\"\n",
    "        )\n",
    "    wd = 0.0\n",
    "    for i in range(ref.shape[0] - k + 1):\n",
    "        ndiff = abs(np.count_nonzero(ref[i : i + k] == boundary) - np.count_nonzero(hyp[i : i + k] == boundary))\n",
    "        if weighted:\n",
    "            wd += ndiff\n",
    "        else:\n",
    "            wd += min(1, ndiff)\n",
    "    return wd / (ref.shape[0] - k + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([int(ch) for ch in \"000000000100\"])\n",
    "s2 = np.array([int(ch) for ch in \"000000100100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowdiff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataset):\n",
    "    model.eval()\n",
    "    total_pk = 0.0\n",
    "    total_windowdiff = 0.0\n",
    "    with tqdm(desc='Validating', total=len(dataset)) as pbar:\n",
    "        for data in dataset:\n",
    "            pbar.update()\n",
    "            target = data['target']\n",
    "            target = target.long()\n",
    "            output = model(data['sentences'])\n",
    "            output_softmax = F.softmax(output, 1)\n",
    "            output_argmax = torch.argmax(output_softmax, dim=1)\n",
    "            total_pk += pk(target.detach().numpy(), output_argmax.detach().numpy())\n",
    "            total_windowdiff += windowdiff(target.detach().numpy(), output_softmax.detach().numpy())\n",
    "    return total_pk / len(dataset), total_windowdiff / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:]).astype(np.float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecModel = load_vectors('wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = 'val_data'\n",
    "val_dataset = SegmentationDataset(val_path, word2vecModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'saved_model'\n",
    "model = torch.load(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 50/50 [06:02<00:00,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "total_pk, total_windowdiff = validate(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11489407921555729"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11489407921555729"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline():\n",
    "    def __init__(self, data, threshold):\n",
    "        self.dataset = data\n",
    "        self.data_len = len(data)\n",
    "        self.threshold = threshold\n",
    "        self.all_labels = []\n",
    "        self.getBaselineLabels()\n",
    "        \n",
    "    def getBaselineLabels(self):\n",
    "        for data in self.dataset:\n",
    "            sentence_labels = [0 for i in range(data['target'].shape[0])]\n",
    "            sentences = data['sentences']\n",
    "            for i in range(1, sentences.shape[0]):\n",
    "                firstSentenceTensor = sentences[i - 1, :, :]\n",
    "                secondSentenceTensor = sentences[i, :, :]\n",
    "                if torch.norm(secondSentenceTensor - firstSentenceTensor).item() > self.threshold:\n",
    "                    sentence_labels[i - 1] = 1\n",
    "            self.all_labels.append(sentence_labels)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        total_pk = 0.0\n",
    "        total_windowdiff = 0.0\n",
    "        with tqdm(desc='Validating Baseline', total=self.data_len) as pbar:\n",
    "            for i in range(self.data_len):\n",
    "                data = self.dataset[i]\n",
    "                pbar.update()\n",
    "                target = data['target']\n",
    "                target = target.long()\n",
    "                pred = self.all_labels[i]\n",
    "                total_pk += pk(target.detach().numpy(), np.array(pred))\n",
    "                total_windowdiff += windowdiff(target.detach().numpy(), np.array(pred))\n",
    "        return total_pk / self.data_len, total_windowdiff / self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = Baseline(val_dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Baseline: 100%|██████████| 50/50 [00:11<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "base_pk, base_windowdiff = b.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04796617029867993"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11583660303029159"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
